{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIABETIC RETINOPATHY DETECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><small>This notebook was used as an easy way to explain my work process, the code here is not intended to run, I attached the last scripts that I ran in the zip file.<small><i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIRST ITERATION \n",
    "\n",
    "My goal for the first iteration of the project was to become familiar with the handling of the data in Bridges, work locally with sample data, and have the first accuracy results after processing the images in Spark. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data \n",
    "During this first stage, I didn't do any preprocess to the data other than resizing all of the images to the same shape. I used the Numpy and the Pillow libraries to load the data. The following code shows the functions I used in Python for this first iteration:   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <i>getImages</i> function, takes a path p given by the user where all of the images are and returns a list of paths to each image.\n",
    "\n",
    "The <i>getLabel</i> function, takes the name of an image and returns the label from the csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getImages(p):\n",
    "    extensions = ['.jpg', '.png', '.gif', '.jpeg']\n",
    "    files = []\n",
    "    for ext in extensions:\n",
    "        files.extend([(p + \"/\" + f) for f in listdir(path) if f.endswith(ext)])\n",
    "    return files\n",
    "\n",
    "def getLabel(labelF):\n",
    "    d = {}\n",
    "    with open(labelF) as f:\n",
    "        for line in f:\n",
    "            (key, val) = line.split(',')\n",
    "            d[key] = val.rstrip()\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function <i>convertImage</i> receives a dictionary d that has all the images with their labels and an image path to upload. It resizes the image and returns it as a Spark's Dense Vector that will be attached to a numpy 2D array.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertImage(d,i):\n",
    "    img = Image.open(i).convert('RGB')\n",
    "    img = img.resize((10, 10), Image.ANTIALIAS) # Very small size for this first iteration\n",
    "    arr = np.array(img)\n",
    "\n",
    "    # make a 1-dimensional view of arr\n",
    "    flat_arr = DenseVector(arr.ravel())\n",
    "\n",
    "    iname = i.split(\"/\")[-1].split(\".\", 1)[0]\n",
    "    label = float(d[iname])\n",
    "\n",
    "    # add name of the file to array\n",
    "    inf_array = (label, flat_arr)\n",
    "\n",
    "    img.close()\n",
    "    print(i)\n",
    "    return inf_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark Processing\n",
    "For this first iteration, I used Spark's KMeans to classify the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    if len(sys.argv) != 3:\n",
    "        print(\"Usage: python_file_name.py <file> <labelF>\", file=sys.stderr)\n",
    "        exit(-1)\n",
    "    path = sys.argv[1] #path to images\n",
    "    labelF = sys.argv[2] #path to label cvs file\n",
    "\n",
    "    images = getImages(path)\n",
    "    vector = []\n",
    "    numImg = 0\n",
    "    d = getLabel(labelF)\n",
    "\n",
    "    # Create Spark ml DataFrame\n",
    "    sc = SparkContext(appName=\"PipelineIteration\")\n",
    "    sqlContext = SQLContext(sc)\n",
    "    for i in images:\n",
    "        vector.append(convertImage(d,i))\n",
    "\n",
    "    print (\"finish image pre\")\n",
    "\n",
    "    schema = StructType([\n",
    "        StructField(\"label\", IntegerType(), True),\n",
    "        StructField(\"features\", VectorUDT(), True)\n",
    "    ])\n",
    "    df = sqlContext.createDataFrame(vector, schema)\n",
    "    df.printSchema()\n",
    "    df.show()\n",
    "    \n",
    "    (trainingData, testData) = df.randomSplit([0.7, 0.3])\n",
    "\n",
    "    kmeans = KMeans().setK(5).setSeed(1).setFeaturesCol('features')\n",
    "    model = kmeans.fit(trainingData)\n",
    "    #centers = model.clusterCenters()\n",
    "\n",
    "    predictions = model.transform(testData) #KMeans gives the answer in Int it should be in Double for the evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Evaluation\n",
    "I used the Spark MulticlassClassificationEvaluator to evaluate the accuracy of the model during this iteration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    #Changing prediction to Double for evaluation\n",
    "    pred = predictions.map(lambda x: (float(x.prediction), x.label))\n",
    "    schema2 = StructType([\n",
    "        StructField(\"prediction\", DoubleType(), True),\n",
    "        StructField(\"label\", DoubleType(), True)\n",
    "    ])\n",
    "\n",
    "    endPred = sqlContext.createDataFrame(pred, schema2)\n",
    "\n",
    "    #Evaluation\n",
    "    predictionAndLabels = endPred.select(\"prediction\", \"label\")\n",
    "    evaluator = MulticlassClassificationEvaluator(metricName=\"precision\")\n",
    "    print(\"Precision:\" + str(evaluator.evaluate(predictionAndLabels)))\n",
    "\n",
    "    sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIRST ITERATION RESULTS\n",
    "\n",
    "### Accurancy\n",
    "The accuracy was very low, I ran the test 5 times in my computer and got 15.2% with a sample data of 2 GB of images (around 100 images), and ran it once on PSC and had a slightly better result of around 17%. I was expecting this result since I had reduced the size too much for performance and KMeans wasn't the best choice for a training the data.\n",
    "\n",
    "### Next Iteration\n",
    "I decided that this iteration was over because I had achieved my goals of becoming familiar with the handling of the data in Bridges, work locally with sample data, and have the first accuracy results after processing the images in Spark. For the next iteration I wanted to focus on finding a model that gave good accurancy and made sense for the challenge and improving my performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECOND ITERATION \n",
    "\n",
    "My goal for the second iteration of the project was to improve significantly my accurancy. Also, I wanted to improve my performance when loading the images so that the work would be easier and it didn't take so long to load all the images, both locally and in Bridges. \n",
    "On the first iteration I constantly had an out of memory error which forced me to decrease the size of the images losing a lot of information and waste a lot of time running the application over and over again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data with Spark and PIL\n",
    "For this iteration, I moved the data loading to another script and save all images in smaller parquet files. I used a pool to load the images. This increased the performance significantly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    NUM_OF_PARTITIONS = 100\n",
    "\n",
    "    if len(sys.argv) != 5:\n",
    "        print(\"Usage: imgToDF.py <pathToImg> <labelF> <parquetName> <partNum>\", file=sys.stderr)\n",
    "        exit(-1)\n",
    "    # path to img (xhan/train)\n",
    "    path = sys.argv[1]\n",
    "    # csv with label for each img (/train/imgLabels.csv)\n",
    "    labelF = sys.argv[2]\n",
    "    # name to save parquet (100x100_1)\n",
    "    parquetName = sys.argv[3]\n",
    "    # number of partition of list of image file (1 would mean 1st partition, there are 4 per folder)\n",
    "    partNum = int(sys.argv[4])\n",
    "\n",
    "    # list with each path to each img\n",
    "    images = np.array_split(getImages(path),NUM_OF_PARTITIONS)\n",
    "\n",
    "    # label for each img\n",
    "    d = getLabel(labelF)\n",
    "\n",
    "    # Loads all images of each partition into a numpy array of 2D\n",
    "    pool = Pool()\n",
    "    func = partial(convertImage, d)\n",
    "    pool_result = pool.map_async(func, images[partNum])\n",
    "\n",
    "    # wait for every worker to finish\n",
    "    pool_result.wait(timeout=5)\n",
    "\n",
    "    # once the timeout has finished we can try to get the results\n",
    "    vector = pool_result.get()\n",
    "\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    # Creates Spark ml DataFrame\n",
    "    sc = SparkContext(appName=\"imgToDF\")\n",
    "    sqlContext = SQLContext(sc)\n",
    "    schema = StructType([\n",
    "        StructField(\"label\", DoubleType(), True),\n",
    "        StructField(\"features\", VectorUDT(), True)\n",
    "    ])\n",
    "    df = sqlContext.createDataFrame(vector, schema)\n",
    "\n",
    "    # Saves DataFrame for later use\n",
    "    name = parquetName + \"_\" +str(partNum)\n",
    "    df.write.save(name, format=\"parquet\")\n",
    "\n",
    "    sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Evaluation\n",
    "\n",
    "I changed the classification algorithm to Random Forest. I used a pipeline that first indexed the labels and then the features and last it fitted the RF model. I used the same Evaluation method as before, the MulticlassClassificationEvaluator from Spark. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    if len(sys.argv) != 5:\n",
    "        print(\"Usage: python_file_name.py <numOfPartitions> <parquet> <numOfPartTest> <parquetTest>\", file=sys.stderr)\n",
    "        exit(-1)\n",
    "    NUM_OF_PARTITIONS = int(sys.argv[1])\n",
    "    parquet = sys.argv[2]\n",
    "    NUM_OF_PARTITIONS_TEST = int(sys.argv[3])\n",
    "    parquetTest = sys.argv[4]\n",
    "\n",
    "    sc = SparkContext(appName=\"PipelineIteration\")\n",
    "    sqlContext = SQLContext(sc)\n",
    "\n",
    "    schema = StructType([\n",
    "        StructField(\"label\", DoubleType(), True),\n",
    "        StructField(\"features\", VectorUDT(), True)\n",
    "    ])\n",
    "\n",
    "    df = sqlContext.createDataFrame([], schema)\n",
    "\n",
    "    for p in range(NUM_OF_PARTITIONS):\n",
    "        name = parquet + \"_\" + str(p)\n",
    "        df = df.unionAll(sqlContext.read.load(name))\n",
    "\n",
    "    # Index labels\n",
    "    labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(df)\n",
    "\n",
    "    print (\"\\n\\n\\n\\n\\n\\n first fit complete \\n\\n\\n\\n\\n\\n\\n\")\n",
    "\n",
    "    # Index the features \n",
    "    featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=5).fit(df)\n",
    "    print(\"\\n\\n\\n\\n\\n\\nfinish featureIndexer\\n\\n\\n\\n\\n\\n\")\n",
    "    \n",
    "    # Split the data into training and test sets (30% held out for testing)\n",
    "    #(trainingData, testData) = df.randomSplit([0.7, 0.3])\n",
    "    #print(\"\\n\\n\\n\\n\\n\\ndata split\\n\\n\\n\\n\\n\\n\")\n",
    "\n",
    "    # Train a RandomForest model.\n",
    "    rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", maxDepth=5, numTrees=20)\n",
    "    print(\"\\n\\n\\n\\n\\n\\nrf created\\n\\n\\n\\n\\n\\n\")\n",
    "\n",
    "    # Chain indexers and forest in a Pipeline\n",
    "    pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf])\n",
    "    print(\"\\n\\n\\n\\n\\n\\npipeline ready\\n\\n\\n\\n\\n\\n\")\n",
    "\n",
    "    # Train model.  This also runs the indexers.\n",
    "    model = pipeline.fit(df)\n",
    "    print(\"\\n\\n\\n\\n\\n\\nmodel ready\\n\\n\\n\\n\\n\\n\")\n",
    "\n",
    "    dfTest = sqlContext.createDataFrame([], schema)\n",
    "\n",
    "    for p in range(NUM_OF_PARTITIONS_TEST):\n",
    "        name = parquetTest + \"_\" + str(p)\n",
    "        df = df.unionAll(sqlContext.read.load(name))\n",
    "    \n",
    "    # Make predictions.\n",
    "    predictions = model.transform(dfTest)\n",
    "    print(\"\\n\\n\\n\\n\\n\\npredictions ready\\n\\n\\n\\n\\n\\n\")\n",
    "\n",
    "    # Select (prediction, true label) and compute test error\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol = \"indexedLabel\", predictionCol = \"prediction\", metricName = \"precision\")\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "\n",
    "    rfModel = model.stages[2] # summary only\n",
    "\n",
    "    # Select example rows to display.\n",
    "    predictions.select(\"prediction\", \"indexedLabel\").show(30)\n",
    "\n",
    "    sc.stop()\n",
    "\n",
    "    with open(\"rrodrigu/results.txt\", \"a\") as myfile:\n",
    "        value = ('Accurancy ' + str(accuracy) + ' rfModel ' + str(rfModel))\n",
    "        myfile.write(str(value)+'\\n')'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECOND ITERATION RESULTS\n",
    "\n",
    "### Accuracy\n",
    "\n",
    "I tested the results throughly before testing them on PSC. When testing locally, I split the data into training and test sets automatically so that it would be easier and faster. A summary of my results is seen in the table below:\n",
    "\n",
    "![Local Data](SampleData.png)\n",
    "\n",
    "After testing the best combinations in Bridges I got the following:\n",
    "\n",
    "![Bridges Data](BridgesResults.png)\n",
    "\n",
    "### Next Iteration\n",
    "I decided that this iteration was over because I had been able to achieve a good performance and I wanted to experiment with Python's image processing libs like opencv and focus more on data preprocess.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THIRD ITERATION\n",
    "My goal for the third iteration of the project was to experiment more with the images and try to improve my accuracy  by trying new feature selection. One thing that I didn't want to do was to use filters that I didn't undestand, I wanted to mimic what my brain does when I recognize an image as sick or healthy, so I based the filters that I used on this, if I wasn't able to really understand what was going on, I didn't use it.\n",
    "Also, I wanted to improve my performance and use bigger images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data with Spark and PIL\n",
    "For this iteration, the script used was similar to the one in the second iteration but I added a new Spark configuration to set the max RAM to a higher size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This configuration lets me have much more RAM in Bridges and I stop having the out of bounds problem.\n",
    "conf = (SparkConf().set(\"spark.driver.maxResultSize\", \"20g\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are the different filters that I tried all with a scale of 200 pixels in my local environment to see \n",
    "which one would give a better accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the Optic Nerve\n",
    "This filter was intended to remove the optic nerve of the image and set it to black. After removing the optic nerve it blurred the image so that the veins would be less intense, removing the noise that they might generate because of their sharp edges. The gain in accuracy for this filter was less than 2% in the sample data and it sometimes failed to recognize the optic nerve adding more noise. I didn't use it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmEyeN(i):\n",
    "    SCALE = 201\n",
    "    # load the image and convert it to grayscale\n",
    "    img = Image.open(i).convert('RGB')\n",
    "    img = img.resize((SCALE, SCALE), Image.ANTIALIAS)\n",
    "    img = np.array(img)\n",
    "\n",
    "    shape = img.shape\n",
    "    orig = img.copy()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # apply a Gaussian blur to the image then find the brightest\n",
    "    # region\n",
    "    radius = SCALE/11\n",
    "    gray = cv2.GaussianBlur(gray, (radius, radius), 0)\n",
    "    (minVal, maxVal, minLoc, maxLoc) = cv2.minMaxLoc(gray)\n",
    "    image = orig.copy()\n",
    "    cv2.circle(image, maxLoc, radius, (0, 0, 0), thickness=-1)\n",
    "\n",
    "    # Blur Veins\n",
    "    blurredImg = cv2.GaussianBlur(image, (7, 7), 0)\n",
    "\n",
    "    # display the results of our newly improved method\n",
    "    # make a PIL image\n",
    "    #img3 = Image.fromarray(blurredImg, 'RGB')\n",
    "    #img3.show()\n",
    "    return blurredImg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color Boundaries\n",
    "This filter was intended to recognize the parts of the image that had the highest tones of red, which I thought to be the veins and remove them. When testing it on the sample data in the local environment the filter didn't increase the accurancy so it was not used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This filter was taken from Adrian Rosebrock's blog\n",
    "def colorBoundaries(img):\n",
    "    # define the list of boundaries\n",
    "    boundaries = [\n",
    "        ([17, 15, 100], [50, 56, 200]),\n",
    "        ([86, 31, 4], [220, 88, 50]),\n",
    "        ([25, 146, 190], [62, 174, 250]),\n",
    "        ([103, 86, 65], [145, 133, 128])\n",
    "    ]\n",
    "\n",
    "    image = cv2.resize(cv2.imread(img), (0, 0), fx=0.25, fy=0.25)\n",
    "\n",
    "    # loop over the boundaries\n",
    "    for (lower, upper) in boundaries:\n",
    "        # create NumPy arrays from the boundaries\n",
    "        lower = np.array(lower, dtype=\"uint8\")\n",
    "        upper = np.array(upper, dtype=\"uint8\")\n",
    "\n",
    "        # find the colors within the specified boundaries and apply\n",
    "        # the mask\n",
    "        mask = cv2.inRange(image, lower, upper)\n",
    "        output = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "        # show the images\n",
    "        #cv2.imshow(\"images\", np.hstack([image, output]))\n",
    "        #cv2.waitKey(0)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Color\n",
    "This filter weighted the average of the color in the image. It made it easier to see the white spots on the eyes and was taken from the winner of the original Kaggle challenge. This filter increased the accuracy on the local environment significally. When testing the Random Forest locally in the second iteration the accuracy was around 54%, with this filter it came to 70%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weightColor(i):\n",
    "\n",
    "    SCALE = 200\n",
    "\n",
    "    # load the image and convert it to grayscale\n",
    "    img = Image.open(i).convert('RGB')\n",
    "    img = img.resize((SCALE, SCALE), Image.ANTIALIAS)\n",
    "    img = np.array(img)\n",
    "    #img = scaleRadius(SCALE,img)\n",
    "    #img = np.array(img)\n",
    "\n",
    "\n",
    "    shape = img.shape\n",
    "    orig = img.copy()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Substract the local average color **got this idea from the winner of the challenge**\n",
    "    img2 = cv2.addWeighted(img, 4, cv2.GaussianBlur(img, (0, 0), SCALE/30), -4, 128)\n",
    "\n",
    "    b= np.zeros(img2.shape)\n",
    "    cv2.circle(b,(img2.shape[1]/2,img2.shape[0]/2),int(SCALE*0.9),(1,1,1),-1,8,0)\n",
    "\n",
    "    a2=img2*b+128*(1-b)\n",
    "\n",
    "    arr2 = np.asarray(img2).reshape(shape)\n",
    "\n",
    "    # make a PIL image\n",
    "    #img3 = Image.fromarray(arr2, 'RGB')\n",
    "    #img3.show()\n",
    "    \n",
    "    return arr2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Color no OpenCV\n",
    "\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weightColorNoCV(i):\n",
    "    SCALE = 200\n",
    "\n",
    "    img = Image.open(i).convert('RGB')\n",
    "    img = img.resize((SCALE, SCALE), Image.ANTIALIAS)  # size of smallest image in the train set, got this with bash\n",
    "    img = np.array(img)\n",
    "    # img = scaleRadius(SCALE,img)\n",
    "\n",
    "    # record the original shape to build it again when testing\n",
    "    shape = img.shape\n",
    "    alpha = np.full(shape, 4, dtype=np.int64)\n",
    "    beta = np.full(shape, -4, dtype=np.int64)\n",
    "    gamma = np.full(shape, 128, dtype=np.int64)\n",
    "    blurred = gaussian_filter(img, sigma=SCALE/40, mode='nearest')\n",
    "\n",
    "    # img2 = cv2.addWeighted(img, 4, cv2.GaussianBlur(img, (0, 0), SCALE / 30), -4, 128)\n",
    "\n",
    "    img2 = img * alpha + blurred*beta + gamma\n",
    "\n",
    "    b = np.zeros(img2.shape)\n",
    "\n",
    "    img3 = img2 + 128 * (1 - b)\n",
    "\n",
    "    #toimage(img3).show()\n",
    "    return img3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third Iteration Results\n",
    "\n",
    "### Accuracy\n",
    "The accuracy was significantly increased by the Weighted Color filter in the local machine from ~54% to ~70%. The other filters didn't provide the expected results. For example, removing the optic nerve with this filter sometimes added noise when the contrast in the border of the eye was too white and it recognized the max there instead of in the optic nerve.\n",
    "\n",

    "### Not accomplished\n",
    "I didn't ran the quadratic_weighted_kappa on bridges, I was able to ran it only locally with about 12 GB of images. The results where similar to the ones obtained with the Spark evaluation.\n",
    "I wasn't able to run a test with the best filter because of the problem with openCV on Bridges so I just ran it with the WeightedColor no open CV but the results only increased slightly from ~73% to ~76% "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
